{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f313d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# CONFIGURATION\n",
    "# Update this path to your actual folder location\n",
    "DATA_DIR = './synthea/' \n",
    "\n",
    "def load_data():\n",
    "    print(\"Loading Synthea CSVs...\")\n",
    "    try:\n",
    "        encounters = pd.read_csv(os.path.join(DATA_DIR, 'encounters.csv'))\n",
    "        patients = pd.read_csv(os.path.join(DATA_DIR, 'patients.csv'))\n",
    "        observations = pd.read_csv(os.path.join(DATA_DIR, 'observations.csv'))\n",
    "        procedures = pd.read_csv(os.path.join(DATA_DIR, 'procedures.csv'))\n",
    "        imaging = pd.read_csv(os.path.join(DATA_DIR, 'imaging_studies.csv'))\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return encounters, patients, observations, procedures, imaging\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Make sure your CSV files are in: {DATA_DIR}\")\n",
    "        return None\n",
    "\n",
    "def process_data(encounters, patients, observations, procedures, imaging):\n",
    "    print(\"Processing Data...\")\n",
    "\n",
    "    # 1. PREPARE PATIENTS (DEMOGRAPHICS) ------------------------\n",
    "    # Calculate Age (approximate based on Encounter date if possible, otherwise static)\n",
    "    patients['BIRTHDATE'] = pd.to_datetime(patients['BIRTHDATE'])\n",
    "    patients = patients[['Id', 'BIRTHDATE', 'GENDER']]\n",
    "    patients.rename(columns={'Id': 'PATIENT'}, inplace=True)\n",
    "\n",
    "    # 2. PREPARE ENCOUNTERS (THE ANCHOR) ------------------------\n",
    "    # We only care about encounters that have a Reason (Symptom)\n",
    "    encounters = encounters[encounters['REASONDESCRIPTION'].notna()]\n",
    "    encounters['START'] = pd.to_datetime(encounters['START'])\n",
    "    \n",
    "    # Merge Patient Demographics into Encounter\n",
    "    df = encounters[['Id', 'PATIENT', 'START', 'REASONDESCRIPTION']].merge(patients, on='PATIENT', how='left')\n",
    "    \n",
    "    # Calculate Age at time of Encounter\n",
    "    df['AGE_AT_VISIT'] = df['START'].dt.year - df['BIRTHDATE'].dt.year\n",
    "    df.drop(columns=['BIRTHDATE', 'START', 'PATIENT'], inplace=True)\n",
    "    df.rename(columns={'Id': 'ENCOUNTER'}, inplace=True)\n",
    "\n",
    "    # 3. SPLIT OBSERVATIONS: VITALS (INPUT) vs LABS (OUTPUT) ----\n",
    "    # Standard LOINC codes for Vitals in Synthea\n",
    "    VITAL_CODES = [\n",
    "        '8302-2', '29463-7', '39156-5', # Height, Weight, BMI\n",
    "        '8480-6', '8462-4', '8867-4',   # Systolic, Diastolic, HR\n",
    "        '9279-1', '59408-5', '8310-5'   # Resp Rate, O2 Sat, Temp\n",
    "    ]\n",
    "\n",
    "    # Split\n",
    "    vitals_df = observations[observations['CODE'].isin(VITAL_CODES)]\n",
    "    labs_df = observations[~observations['CODE'].isin(VITAL_CODES)]\n",
    "\n",
    "    # 3a. Process Vitals (Pivot to wide format for Input Features)\n",
    "    # We take the mean if multiple vitals exist per encounter\n",
    "    vitals_pivot = vitals_df.pivot_table(\n",
    "        index='ENCOUNTER', \n",
    "        columns='DESCRIPTION', \n",
    "        values='VALUE', \n",
    "        aggfunc='first' # Synthea values are strings, simplified here\n",
    "    )\n",
    "    # Convert numeric vitals (forcing errors to NaN)\n",
    "    vitals_pivot = vitals_pivot.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # 3b. Process Labs (Target Variable)\n",
    "    # We just want the NAME of the test ordered\n",
    "    labs_df = labs_df[['ENCOUNTER', 'DESCRIPTION']].rename(columns={'DESCRIPTION': 'TEST_NAME'})\n",
    "\n",
    "    # 4. PROCESS PROCEDURES & IMAGING (TARGET VARIABLES) --------\n",
    "    procs_df = procedures[['ENCOUNTER', 'DESCRIPTION']].rename(columns={'DESCRIPTION': 'TEST_NAME'})\n",
    "    imgs_df = imaging[['ENCOUNTER', 'BODYSITE_DESCRIPTION', 'MODALITY_DESCRIPTION']]\n",
    "    \n",
    "    # Combine Imaging fields into one test name (e.g., \"Chest X-ray\")\n",
    "    imgs_df['TEST_NAME'] = imgs_df['BODYSITE_DESCRIPTION'] + \" \" + imgs_df['MODALITY_DESCRIPTION']\n",
    "    imgs_df = imgs_df[['ENCOUNTER', 'TEST_NAME']]\n",
    "\n",
    "    # 5. COMBINE ALL TARGETS (LABS + PROCS + IMAGING) -----------\n",
    "    all_tests = pd.concat([labs_df, procs_df, imgs_df])\n",
    "    \n",
    "    # Group by encounter to get a list of tests per visit\n",
    "    tests_grouped = all_tests.groupby('ENCOUNTER')['TEST_NAME'].apply(list).reset_index()\n",
    "    tests_grouped.rename(columns={'TEST_NAME': 'TARGET_TESTS'}, inplace=True)\n",
    "\n",
    "    # 6. FINAL MERGE --------------------------------------------\n",
    "    # Master DF = Encounters + Vitals + Test Lists\n",
    "    master_df = df.merge(vitals_pivot, on='ENCOUNTER', how='left')\n",
    "    master_df = master_df.merge(tests_grouped, on='ENCOUNTER', how='inner')\n",
    "\n",
    "    # Fill Missing Vitals with 0 or Mean (Simplified for this script)\n",
    "    master_df.fillna(0, inplace=True)\n",
    "\n",
    "    print(f\"Processing complete. Created dataset with {len(master_df)} encounters.\")\n",
    "    return master_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_data()\n",
    "    if data:\n",
    "        clean_df = process_data(*data)\n",
    "        clean_df.to_csv(\"training_data_model_2.csv\", index=False)\n",
    "        print(\"Saved cleaned data to 'training_data_model_2.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# 1. LOAD DATA ------------------------------------------------\n",
    "print(\"1. Loading cleaned dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv(\"training_data_model_2.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'training_data_model_2.csv' not found. Please run process_synthea_data.py first.\")\n",
    "    # Exit gracefully if the required file is missing\n",
    "    raise\n",
    "\n",
    "# Parse the string representation of list back to actual list\n",
    "# (CSV saves lists as strings like \"['ECG', 'Xray']\")\n",
    "df['TARGET_TESTS'] = df['TARGET_TESTS'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# Filter out rows where no tests were ordered (empty lists)\n",
    "df = df[df['TARGET_TESTS'].apply(len) > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded and filtered down to {len(df)} samples with valid tests.\")\n",
    "\n",
    "# 2. PREPARE FEATURES (X) AND TARGETS (Y) ---------------------\n",
    "\n",
    "# Y: Target Tests (Multi-label)\n",
    "# Example: [0, 1, 0, 1] meaning \"Test B and Test D ordered\"\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['TARGET_TESTS'])\n",
    "print(f\"Model will predict {len(mlb.classes_)} unique test types.\")\n",
    "\n",
    "# X: Input Features\n",
    "# Separate text features from numeric/categorical\n",
    "X = df.drop(columns=['ENCOUNTER', 'TARGET_TESTS'])\n",
    "\n",
    "# Identify column types\n",
    "text_features = 'REASONDESCRIPTION'\n",
    "categorical_features = ['GENDER']\n",
    "# The remaining columns are our numeric features (Vitals, Age, etc.)\n",
    "numeric_features = [col for col in X.columns if col not in [text_features] + categorical_features]\n",
    "\n",
    "# Ensure the columns for the sample prediction are available in the training data\n",
    "print(\"Input Features:\", X.columns.tolist())\n",
    "\n",
    "# 3. BUILD THE PIPELINE ---------------------------------------\n",
    "\n",
    "# A. Preprocessing Inputs\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # TF-IDF for the symptom description\n",
    "        ('txt', TfidfVectorizer(max_features=500, stop_words='english'), text_features), \n",
    "        # OneHotEncoding for GENDER\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        # Pass through all Vitals and Age\n",
    "        ('num', 'passthrough', numeric_features)\n",
    "    ])\n",
    "\n",
    "# B. The Classifier\n",
    "# We use Random Forest wrapped in MultiOutputClassifier\n",
    "# RandomForest is robust to missing feature interactions, which is good for clinical data.\n",
    "clf = MultiOutputClassifier(RandomForestClassifier(n_estimators=150, max_depth=10, random_state=42, class_weight='balanced_subsample'))\n",
    "\n",
    "# C. Assemble Pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# 4. TRAIN AND EVALUATE ---------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\n2. Training The Strategist (Model 2)...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training Complete.\")\n",
    "\n",
    "print(\"\\n3. Evaluating Model Performance...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Macro F1 Score (critical metric for multi-label classification)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "print(f\"Macro F1 Score (Overall Test Recommendation Quality): {f1_macro:.4f}\")\n",
    "\n",
    "# Detailed per-test report\n",
    "print(\"\\nDetailed Per-Test Precision/Recall (Top 10 Tests):\")\n",
    "report = classification_report(y_test, y_pred, target_names=mlb.classes_, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report).transpose().sort_values(by='f1-score', ascending=False)\n",
    "print(report_df.head(10).to_markdown(floatfmt=\".2f\"))\n",
    "\n",
    "\n",
    "# 5. DEMO PREDICTION ------------------------------------------\n",
    "print(\"\\n4. Running Live Demo Prediction...\")\n",
    "\n",
    "# Sample patient with classic cardiac symptoms and elevated vitals\n",
    "sample_patient_data = {\n",
    "    'REASONDESCRIPTION': 'Severe chest tightness and shortness of breath.', \n",
    "    'GENDER': 'M',\n",
    "    'AGE_AT_VISIT': 68,\n",
    "    'Body Height': 175,\n",
    "    'Body Weight': 85,\n",
    "    'Heart rate': 115, # Elevated HR\n",
    "    'Systolic Blood Pressure': 155,\n",
    "    'Diastolic Blood Pressure': 95,\n",
    "    'Respiratory rate': 22, # Elevated RR\n",
    "    'Body Mass Index': 27.7,\n",
    "    'Oxygen saturation in Arterial blood': 96,\n",
    "    'Body temperature': 37.5\n",
    "}\n",
    "\n",
    "# Create DataFrame for prediction\n",
    "sample_patient = pd.DataFrame([sample_patient_data])\n",
    "\n",
    "# Ensure all expected columns are present, even if zero-filled in this sample\n",
    "for col in numeric_features:\n",
    "    if col not in sample_patient.columns:\n",
    "        sample_patient[col] = 0\n",
    "\n",
    "prediction_bin = model.predict(sample_patient)\n",
    "predicted_tests = mlb.inverse_transform(prediction_bin)\n",
    "\n",
    "print(f\"\\nPatient Complaint: {sample_patient['REASONDESCRIPTION'].iloc[0]}\")\n",
    "print(f\"Patient Vitals: Age {sample_patient['AGE_AT_VISIT'].iloc[0]}, HR {sample_patient['Heart rate'].iloc[0]}\")\n",
    "print(\"---\")\n",
    "print(f\"Recommended Tests (The Strategist): {predicted_tests[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c47e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"AGBonnet/augmented-clinical-notes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_tests_dataset.py\n",
    "import json\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# ------- CONFIG -------\n",
    "HF_ID = \"AGBonnet/augmented-clinical-notes\"  # <-- change to your HF dataset id\n",
    "SPLIT = \"train\"        # or \"all\" / whichever split exists\n",
    "TEXT_COL_CANDIDATES = [\"text\", \"note\", \"full_note\", \"summary\", \"conversation\", \"report\"]\n",
    "SUMMARY_COL = \"summary\"   # if dataset has explicit 'summary' column\n",
    "OUT_DIR = \"prepared_data\"\n",
    "TEST_SIZE = 0.1\n",
    "RANDOM_STATE = 42\n",
    "MIN_LABEL_FREQ = 2   # labels seen less than this will be grouped as 'other' (optional)\n",
    "# ----------------------\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def try_parse_json_maybe(s):\n",
    "    \"\"\"If s is a JSON string, parse it; otherwise return s.\"\"\"\n",
    "    if s is None:\n",
    "        return None\n",
    "    if isinstance(s, (dict, list)):\n",
    "        return s\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    s_stripped = s.strip()\n",
    "    # Heuristics: starts with { or [\n",
    "    if s_stripped.startswith(\"{\") or s_stripped.startswith(\"[\"):\n",
    "        try:\n",
    "            return json.loads(s_stripped)\n",
    "        except Exception:\n",
    "            # sometimes it's escaped; try un-escaping common patterns\n",
    "            s_unq = s_stripped.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "            try:\n",
    "                return json.loads(s_unq)\n",
    "            except Exception:\n",
    "                return s\n",
    "    return s\n",
    "\n",
    "def find_text_column(example):\n",
    "    \"\"\"Return first candidate that exists in example.\"\"\"\n",
    "    for c in TEXT_COL_CANDIDATES:\n",
    "        if c in example:\n",
    "            return c\n",
    "    # fallback: choose the longest string column\n",
    "    text_cols = [k for k, v in example.items() if isinstance(v, str)]\n",
    "    if not text_cols:\n",
    "        return None\n",
    "    # return column with the largest average length (heuristic)\n",
    "    return max(text_cols, key=lambda k: len(str(example.get(k) or \"\")))\n",
    "\n",
    "def extract_tests_from_summary(summary_obj):\n",
    "    \"\"\"\n",
    "    summary_obj may be dict or string. We expect a field like \"diagnosis tests\"\n",
    "    which can be a list of dicts where each dict has a \"test\" key.\n",
    "    Returns list of strings (test names).\n",
    "    \"\"\"\n",
    "    if summary_obj is None:\n",
    "        return []\n",
    "    # if string, try parse\n",
    "    parsed = try_parse_json_maybe(summary_obj)\n",
    "    if isinstance(parsed, str):\n",
    "        # could be plain text that mentions tests; fallback empty\n",
    "        return []\n",
    "    if isinstance(parsed, list):\n",
    "        # maybe list of entries each containing diagnosis tests\n",
    "        # check each element for \"diagnosis tests\"\n",
    "        aggregated = []\n",
    "        for p in parsed:\n",
    "            aggregated += extract_tests_from_summary(p)\n",
    "        return aggregated\n",
    "    if isinstance(parsed, dict):\n",
    "        # try keys that could indicate diag tests\n",
    "        diag_keys = [k for k in parsed.keys() if \"diagnos\" in k.lower() or \"test\" in k.lower()]\n",
    "        # prefer exact matches\n",
    "        prefer = [\"diagnosis tests\", \"diagnosis_tests\", \"diagnosis\", \"diagnosis test\", \"diagnosis_tests_list\"]\n",
    "        key = None\n",
    "        for p in prefer:\n",
    "            if p in parsed:\n",
    "                key = p; break\n",
    "        if key is None:\n",
    "            key = diag_keys[0] if diag_keys else None\n",
    "\n",
    "        if key:\n",
    "            val = parsed.get(key)\n",
    "            if val is None:\n",
    "                return []\n",
    "            if isinstance(val, list):\n",
    "                tests = []\n",
    "                for t in val:\n",
    "                    if isinstance(t, dict):\n",
    "                        # common subkey names\n",
    "                        for tk in (\"test\", \"name\", \"exam\", \"procedure\"):\n",
    "                            if tk in t:\n",
    "                                tests.append(t[tk])\n",
    "                                break\n",
    "                        else:\n",
    "                            # try any string value inside dict\n",
    "                            for v in t.values():\n",
    "                                if isinstance(v, str) and len(v) < 200:\n",
    "                                    tests.append(v); break\n",
    "                    elif isinstance(t, str):\n",
    "                        tests.append(t)\n",
    "                return [str(x).strip() for x in tests if x]\n",
    "            if isinstance(val, dict):\n",
    "                # single dict\n",
    "                for tk in (\"test\", \"name\", \"exam\", \"procedure\"):\n",
    "                    if tk in val:\n",
    "                        return [val[tk]]\n",
    "                # fallback: flatten string values\n",
    "                return [str(v) for v in val.values() if isinstance(v, str)]\n",
    "        # No diag key found - maybe the parsed dict is the whole note; search nested keys\n",
    "        # search recursively\n",
    "        tests = []\n",
    "        for v in parsed.values():\n",
    "            if isinstance(v, (list, dict)):\n",
    "                tests += extract_tests_from_summary(v)\n",
    "        return tests\n",
    "    return []\n",
    "\n",
    "def normalize_test_name(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    # lowercase, collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s).lower()\n",
    "    # common normalizations\n",
    "    s = s.replace(\"magnetic resonance imaging\", \"mri\")\n",
    "    s = s.replace(\"computed tomography\", \"ct\")\n",
    "    s = s.replace(\"x-ray\", \"xray\")\n",
    "    s = s.replace(\"x ray\", \"xray\")\n",
    "    s = s.replace(\"radiograph\", \"xray\")\n",
    "    s = s.replace(\"electromyography\", \"emg\")\n",
    "    s = s.replace(\"nerve conduction study\", \"ncs\")\n",
    "    s = s.replace(\"biopsy\", \"biopsy\")\n",
    "    s = s.replace(\"ultrasound\", \"ultrasound\")\n",
    "    s = s.replace(\"ct-scan\", \"ct\")\n",
    "    # remove punctuation\n",
    "    s = re.sub(r\"[^\\w\\s/+-]\", \"\", s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def load_and_prepare(hf_id, split):\n",
    "    ds = load_dataset(hf_id) if \":\" not in hf_id else load_dataset(*hf_id.split(\":\"))\n",
    "    # choose split\n",
    "    chosen_split = split if split in ds else (\"train\" if \"train\" in ds else list(ds.keys())[0])\n",
    "    d = ds[chosen_split]\n",
    "    rows = []\n",
    "    text_col = None\n",
    "    # detect text column on first example\n",
    "    first = d[0]\n",
    "    text_col = find_text_column(first)\n",
    "    print(\"Detected text column:\", text_col)\n",
    "    for i, ex in enumerate(d):\n",
    "        # get full text (prefer text_col)\n",
    "        text = ex.get(text_col) if text_col and text_col in ex else None\n",
    "        # if text is missing, check 'summary' or other string fields\n",
    "        if not text:\n",
    "            if SUMMARY_COL in ex and ex[SUMMARY_COL]:\n",
    "                # sometimes summary is JSON string containing the full note; try parsing and extracting narrative fields:\n",
    "                parsed = try_parse_json_maybe(ex[SUMMARY_COL])\n",
    "                # pick some long string inside parsed\n",
    "                if isinstance(parsed, dict):\n",
    "                    # prefer keys that look like \"visit motivation\"/\"history\"/\"presentation\"\n",
    "                    narrative_keys = [k for k in parsed.keys() if any(w in k.lower() for w in (\"visit\", \"present\", \"history\", \"motivation\", \"complaint\", \"note\"))]\n",
    "                    if narrative_keys:\n",
    "                        text = \" \".join(str(parsed[k]) for k in narrative_keys if parsed.get(k))\n",
    "                if not text:\n",
    "                    # fallback to entire summary as string\n",
    "                    text = str(parsed) if parsed else \"\"\n",
    "        # ensure text is string\n",
    "        text = str(text) if text is not None else \"\"\n",
    "\n",
    "        # extract tests from summary field if available; else search inside the whole example\n",
    "        summary_obj = ex.get(SUMMARY_COL) if SUMMARY_COL in ex else None\n",
    "        tests = extract_tests_from_summary(summary_obj)\n",
    "        if not tests:\n",
    "            # fallback: try scanning entire example for 'diagnosis tests' pattern\n",
    "            tests = extract_tests_from_summary(ex)\n",
    "        # normalize\n",
    "        tests_norm = [normalize_test_name(t) for t in tests if t]\n",
    "        # dedupe\n",
    "        tests_norm = list(dict.fromkeys(tests_norm))\n",
    "        rows.append({\"text\": text, \"tests\": tests_norm, \"original_index\": i})\n",
    "    return rows\n",
    "\n",
    "def build_label_map(rows, min_freq=1):\n",
    "    # collect all labels\n",
    "    cnt = Counter()\n",
    "    for r in rows:\n",
    "        cnt.update(r[\"tests\"])\n",
    "    # optionally drop rare labels or keep them\n",
    "    labels = [lbl for lbl, c in cnt.items() if c >= min_freq and lbl]\n",
    "    labels = sorted(labels)\n",
    "    label2id = {l: i for i, l in enumerate(labels)}\n",
    "    return labels, label2id\n",
    "\n",
    "def encode_multilabel(rows, label2id):\n",
    "    X = []\n",
    "    y = []\n",
    "    for r in rows:\n",
    "        X.append(r[\"text\"])\n",
    "        vec = [0] * len(label2id)\n",
    "        for t in r[\"tests\"]:\n",
    "            if t in label2id:\n",
    "                vec[label2id[t]] = 1\n",
    "        y.append(vec)\n",
    "    return X, y\n",
    "\n",
    "def main():\n",
    "    rows = load_and_prepare(HF_ID, SPLIT)\n",
    "    print(f\"Extracted {len(rows)} rows. Example tests from first rows:\")\n",
    "    for r in rows[:5]:\n",
    "        print(r[\"tests\"])\n",
    "    labels, label2id = build_label_map(rows, min_freq=MIN_LABEL_FREQ)\n",
    "    print(\"Found labels:\", labels)\n",
    "    X, y = encode_multilabel(rows, label2id)\n",
    "\n",
    "    # train/valid split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "    # save CSVs\n",
    "    df_train = pd.DataFrame({\"text\": X_train, \"labels\": [json.dumps(v) for v in y_train]})\n",
    "    df_val = pd.DataFrame({\"text\": X_val, \"labels\": [json.dumps(v) for v in y_val]})\n",
    "    train_csv = os.path.join(OUT_DIR, \"train.csv\")\n",
    "    val_csv = os.path.join(OUT_DIR, \"valid.csv\")\n",
    "    df_train.to_csv(train_csv, index=False)\n",
    "    df_val.to_csv(val_csv, index=False)\n",
    "    print(\"Saved:\", train_csv, val_csv)\n",
    "\n",
    "    # also save a HF Dataset object with encoded labels as list[int]\n",
    "    ds_train = Dataset.from_dict({\"text\": X_train, \"labels\": y_train})\n",
    "    ds_val = Dataset.from_dict({\"text\": X_val, \"labels\": y_val})\n",
    "    ds_all = DatasetDict({\"train\": ds_train, \"validation\": ds_val})\n",
    "    ds_all.save_to_disk(os.path.join(OUT_DIR, \"hf_prepared\"))\n",
    "    print(\"Saved HF dataset to\", os.path.join(OUT_DIR, \"hf_prepared\"))\n",
    "\n",
    "    # save label mapping\n",
    "    with open(os.path.join(OUT_DIR, \"label2id.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(label2id, f, ensure_ascii=False, indent=2)\n",
    "    with open(os.path.join(OUT_DIR, \"labels.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(labels))\n",
    "    print(\"Saved label mapping.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047ae95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9636dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import io\n",
    "\n",
    "# Define symptom categories with base risk scores\n",
    "symptoms = {\n",
    "    # Cardiovascular (high risk)\n",
    "    'chest_pain': (70, 95), 'severe_chest_pain': (85, 98),\n",
    "    'irregular_heartbeat': (60, 85), 'rapid_heartbeat': (50, 75),\n",
    "    'shortness_of_breath': (55, 80), 'severe_shortness_of_breath': (75, 95),\n",
    "    \n",
    "    # Neurological (high risk)\n",
    "    'severe_headache': (65, 90), 'migraine': (40, 65),\n",
    "    'dizziness': (35, 60), 'severe_dizziness': (60, 85),\n",
    "    'confusion': (70, 92), 'loss_of_consciousness': (90, 99),\n",
    "    'seizure': (85, 98), 'slurred_speech': (75, 95),\n",
    "    'vision_problems': (50, 75), 'severe_vision_loss': (80, 96),\n",
    "    \n",
    "    # Respiratory (medium-high risk)\n",
    "    'cough': (20, 45), 'persistent_cough': (40, 65),\n",
    "    'wheezing': (45, 70), 'difficulty_breathing': (65, 88),\n",
    "    'coughing_blood': (80, 95), 'chest_tightness': (50, 75),\n",
    "    \n",
    "    # Gastrointestinal (medium risk)\n",
    "    'nausea': (25, 50), 'vomiting': (35, 60),\n",
    "    'severe_vomiting': (55, 80), 'abdominal_pain': (40, 70),\n",
    "    'severe_abdominal_pain': (70, 92), 'diarrhea': (25, 50),\n",
    "    'bloody_stool': (75, 93), 'constipation': (15, 40),\n",
    "    \n",
    "    # Infectious/Inflammatory (medium risk)\n",
    "    'fever': (30, 60), 'high_fever': (60, 85),\n",
    "    'chills': (25, 50), 'night_sweats': (35, 60),\n",
    "    'swollen_lymph_nodes': (40, 65), 'rash': (20, 50),\n",
    "    'severe_rash': (50, 75),\n",
    "    \n",
    "    # Musculoskeletal (low-medium risk)\n",
    "    'joint_pain': (25, 50), 'muscle_pain': (20, 45),\n",
    "    'back_pain': (30, 55), 'severe_back_pain': (55, 80),\n",
    "    'neck_pain': (25, 50), 'stiffness': (20, 45),\n",
    "    \n",
    "    # General symptoms (low-medium risk)\n",
    "    'fatigue': (20, 45), 'extreme_fatigue': (45, 70),\n",
    "    'weakness': (35, 60), 'loss_of_appetite': (30, 55),\n",
    "    'weight_loss': (40, 70), 'rapid_weight_loss': (65, 88),\n",
    "    'dehydration': (45, 70), 'severe_dehydration': (70, 90),\n",
    "    \n",
    "    # Skin/External (low-medium risk)\n",
    "    'bruising': (25, 50), 'excessive_bruising': (55, 78),\n",
    "    'bleeding': (60, 85), 'swelling': (30, 55),\n",
    "    'severe_swelling': (60, 83), 'pale_skin': (35, 60),\n",
    "    \n",
    "    # Urinary (medium risk)\n",
    "    'painful_urination': (40, 65), 'frequent_urination': (30, 55),\n",
    "    'blood_in_urine': (70, 90), 'difficulty_urinating': (50, 75),\n",
    "    \n",
    "    # Mental Health (medium risk)\n",
    "    'anxiety': (30, 55), 'severe_anxiety': (55, 78),\n",
    "    'depression': (40, 65), 'severe_depression': (65, 85),\n",
    "    'panic_attack': (60, 80), 'insomnia': (25, 50),\n",
    "}\n",
    "\n",
    "# Additional modifiers\n",
    "age_groups = ['child', 'young_adult', 'adult', 'senior']\n",
    "severity_levels = ['mild', 'moderate', 'severe']\n",
    "duration = ['acute', 'chronic', 'intermittent']\n",
    "comorbidities = ['none', 'diabetes', 'hypertension', 'heart_disease', 'asthma']\n",
    "\n",
    "# Generate 2000 entries\n",
    "output = io.StringIO()\n",
    "writer = csv.writer(output)\n",
    "\n",
    "# Write header\n",
    "writer.writerow(['symptom', 'age_group', 'severity', 'duration', 'comorbidity', 'risk_score'])\n",
    "\n",
    "for i in range(2000):\n",
    "    # Select random symptom\n",
    "    symptom = random.choice(list(symptoms.keys()))\n",
    "    base_risk_min, base_risk_max = symptoms[symptom]\n",
    "    \n",
    "    # Select modifiers\n",
    "    age = random.choice(age_groups)\n",
    "    severity = random.choice(severity_levels)\n",
    "    dur = random.choice(duration)\n",
    "    comorbidity = random.choice(comorbidities)\n",
    "    \n",
    "    # Calculate risk score with modifiers\n",
    "    base_risk = random.randint(base_risk_min, base_risk_max)\n",
    "    \n",
    "    # Age modifier\n",
    "    if age == 'senior':\n",
    "        base_risk = min(100, base_risk + random.randint(5, 15))\n",
    "    elif age == 'child':\n",
    "        base_risk = min(100, base_risk + random.randint(3, 10))\n",
    "    \n",
    "    # Severity modifier\n",
    "    if severity == 'severe':\n",
    "        base_risk = min(100, base_risk + random.randint(10, 20))\n",
    "    elif severity == 'mild':\n",
    "        base_risk = max(1, base_risk - random.randint(10, 20))\n",
    "    \n",
    "    # Duration modifier\n",
    "    if dur == 'chronic':\n",
    "        base_risk = min(100, base_risk + random.randint(5, 12))\n",
    "    \n",
    "    # Comorbidity modifier\n",
    "    if comorbidity != 'none':\n",
    "        base_risk = min(100, base_risk + random.randint(8, 18))\n",
    "    \n",
    "    # Ensure risk score is between 1 and 100\n",
    "    risk_score = max(1, min(100, base_risk))\n",
    "    \n",
    "    writer.writerow([symptom, age, severity, dur, comorbidity, risk_score])\n",
    "\n",
    "# Get the CSV content\n",
    "csv_content = output.getvalue()\n",
    "output.close()\n",
    "\n",
    "# Print first 20 rows as preview\n",
    "print(\"Preview of first 20 rows:\")\n",
    "print(\"=\" * 80)\n",
    "lines = csv_content.split('\\n')[:21]\n",
    "for line in lines:\n",
    "    print(line)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nTotal entries generated: 2000\")\n",
    "print(\"\\nTo save this data, copy the output below:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n\" + csv_content)\n",
    "print(len(csv_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import io\n",
    "\n",
    "# Define symptom categories with base risk scores\n",
    "symptoms = {\n",
    "    'chest_pain': (70, 95), 'severe_chest_pain': (85, 98),\n",
    "    'irregular_heartbeat': (60, 85), 'rapid_heartbeat': (50, 75),\n",
    "    'shortness_of_breath': (55, 80), 'severe_shortness_of_breath': (75, 95),\n",
    "    'severe_headache': (65, 90), 'migraine': (40, 65),\n",
    "    'dizziness': (35, 60), 'severe_dizziness': (60, 85),\n",
    "    'confusion': (70, 92), 'loss_of_consciousness': (90, 99),\n",
    "    'seizure': (85, 98), 'slurred_speech': (75, 95),\n",
    "    'vision_problems': (50, 75), 'severe_vision_loss': (80, 96),\n",
    "    'cough': (20, 45), 'persistent_cough': (40, 65),\n",
    "    'wheezing': (45, 70), 'difficulty_breathing': (65, 88),\n",
    "    'coughing_blood': (80, 95), 'chest_tightness': (50, 75),\n",
    "    'nausea': (25, 50), 'vomiting': (35, 60),\n",
    "    'severe_vomiting': (55, 80), 'abdominal_pain': (40, 70),\n",
    "    'severe_abdominal_pain': (70, 92), 'diarrhea': (25, 50),\n",
    "    'bloody_stool': (75, 93), 'constipation': (15, 40),\n",
    "    'fever': (30, 60), 'high_fever': (60, 85),\n",
    "    'chills': (25, 50), 'night_sweats': (35, 60),\n",
    "    'swollen_lymph_nodes': (40, 65), 'rash': (20, 50),\n",
    "    'severe_rash': (50, 75),\n",
    "    'joint_pain': (25, 50), 'muscle_pain': (20, 45),\n",
    "    'back_pain': (30, 55), 'severe_back_pain': (55, 80),\n",
    "    'neck_pain': (25, 50), 'stiffness': (20, 45),\n",
    "    'fatigue': (20, 45), 'extreme_fatigue': (45, 70),\n",
    "    'weakness': (35, 60), 'loss_of_appetite': (30, 55),\n",
    "    'weight_loss': (40, 70), 'rapid_weight_loss': (65, 88),\n",
    "    'dehydration': (45, 70), 'severe_dehydration': (70, 90),\n",
    "    'bruising': (25, 50), 'excessive_bruising': (55, 78),\n",
    "    'bleeding': (60, 85), 'swelling': (30, 55),\n",
    "    'severe_swelling': (60, 83), 'pale_skin': (35, 60),\n",
    "    'painful_urination': (40, 65), 'frequent_urination': (30, 55),\n",
    "    'blood_in_urine': (70, 90), 'difficulty_urinating': (50, 75),\n",
    "    'anxiety': (30, 55), 'severe_anxiety': (55, 78),\n",
    "    'depression': (40, 65), 'severe_depression': (65, 85),\n",
    "    'panic_attack': (60, 80), 'insomnia': (25, 50),\n",
    "}\n",
    "\n",
    "# Additional modifiers\n",
    "age_groups = ['child', 'young_adult', 'adult', 'senior']\n",
    "severity_levels = ['mild', 'moderate', 'severe']\n",
    "duration = ['acute', 'chronic', 'intermittent']\n",
    "comorbidities = ['none', 'diabetes', 'hypertension', 'heart_disease', 'asthma']\n",
    "\n",
    "# Generate 2000 entries\n",
    "output = io.StringIO()\n",
    "writer = csv.writer(output)\n",
    "\n",
    "# Write header\n",
    "writer.writerow(['symptom', 'age_group', 'severity', 'duration', 'comorbidity', 'risk_score'])\n",
    "\n",
    "for i in range(2000):\n",
    "    symptom = random.choice(list(symptoms.keys()))\n",
    "    base_risk_min, base_risk_max = symptoms[symptom]\n",
    "    age = random.choice(age_groups)\n",
    "    severity = random.choice(severity_levels)\n",
    "    dur = random.choice(duration)\n",
    "    comorbidity = random.choice(comorbidities)\n",
    "    base_risk = random.randint(base_risk_min, base_risk_max)\n",
    "\n",
    "    # Age modifier\n",
    "    if age == 'senior':\n",
    "        base_risk = min(100, base_risk + random.randint(5, 15))\n",
    "    elif age == 'child':\n",
    "        base_risk = min(100, base_risk + random.randint(3, 10))\n",
    "\n",
    "    # Severity modifier\n",
    "    if severity == 'severe':\n",
    "        base_risk = min(100, base_risk + random.randint(10, 20))\n",
    "    elif severity == 'mild':\n",
    "        base_risk = max(1, base_risk - random.randint(10, 20))\n",
    "\n",
    "    # Duration modifier\n",
    "    if dur == 'chronic':\n",
    "        base_risk = min(100, base_risk + random.randint(5, 12))\n",
    "\n",
    "    # Comorbidity modifier\n",
    "    if comorbidity != 'none':\n",
    "        base_risk = min(100, base_risk + random.randint(8, 18))\n",
    "\n",
    "    risk_score = max(1, min(100, base_risk))\n",
    "    writer.writerow([symptom, age, severity, dur, comorbidity, risk_score])\n",
    "\n",
    "csv_content = output.getvalue()\n",
    "output.close()\n",
    "\n",
    "# Count total rows (including header)\n",
    "rows = csv_content.strip().split('\\n')\n",
    "total_rows = len(rows)\n",
    "print(f\"Total rows in CSV (including header): {total_rows}\")\n",
    "print(f\"Total data rows in CSV (excluding header): {total_rows - 1}\")\n",
    "\n",
    "# Save the CSV content to a file\n",
    "with open('generated_symptom_risk_data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "print(\"CSV file saved as 'generated_symptom_risk_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd31a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"generated_symptom_risk_data.csv\")\n",
    "\n",
    "# Create binary target\n",
    "df[\"target\"] = (df[\"risk_score\"] >= 70).astype(int)\n",
    "\n",
    "categorical_features = [\"symptom\", \"age_group\", \"severity\", \"duration\", \"comorbidity\"]\n",
    "encoders = {}\n",
    "\n",
    "# Fit encoders and transform\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "X = df[categorical_features]\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 manually chosen test cases from your dataset\n",
    "test_cases = pd.DataFrame([\n",
    "    {\"symptom\": \"bleeding\",           \"age_group\": \"adult\",       \"severity\": \"mild\",     \"duration\": \"acute\",        \"comorbidity\": \"none\",          \"true_target\": 0},\n",
    "    {\"symptom\": \"insomnia\",           \"age_group\": \"senior\",      \"severity\": \"moderate\", \"duration\": \"acute\",        \"comorbidity\": \"none\",          \"true_target\": 0},\n",
    "    {\"symptom\": \"bloody_stool\",       \"age_group\": \"child\",       \"severity\": \"mild\",     \"duration\": \"chronic\",      \"comorbidity\": \"asthma\",        \"true_target\": 1},\n",
    "    {\"symptom\": \"seizure\",            \"age_group\": \"senior\",      \"severity\": \"moderate\", \"duration\": \"chronic\",      \"comorbidity\": \"hypertension\",  \"true_target\": 1},\n",
    "    {\"symptom\": \"chest_pain\",         \"age_group\": \"child\",       \"severity\": \"mild\",     \"duration\": \"acute\",        \"comorbidity\": \"heart_disease\", \"true_target\": 1},\n",
    "    {\"symptom\": \"fatigue\",            \"age_group\": \"young_adult\", \"severity\": \"moderate\", \"duration\": \"acute\",        \"comorbidity\": \"asthma\",        \"true_target\": 0},\n",
    "    {\"symptom\": \"severe_chest_pain\",  \"age_group\": \"senior\",      \"severity\": \"mild\",     \"duration\": \"intermittent\", \"comorbidity\": \"asthma\",        \"true_target\": 1},\n",
    "    {\"symptom\": \"severe_depression\",  \"age_group\": \"young_adult\", \"severity\": \"severe\",   \"duration\": \"intermittent\", \"comorbidity\": \"diabetes\",      \"true_target\": 1},\n",
    "    {\"symptom\": \"severe_dehydration\", \"age_group\": \"senior\",      \"severity\": \"mild\",     \"duration\": \"intermittent\", \"comorbidity\": \"diabetes\",      \"true_target\": 1},\n",
    "    {\"symptom\": \"diarrhea\",           \"age_group\": \"adult\",       \"severity\": \"mild\",     \"duration\": \"acute\",        \"comorbidity\": \"none\",          \"true_target\": 0},\n",
    "    {\"symptom\": \"bruising\",           \"age_group\": \"child\",       \"severity\": \"severe\",   \"duration\": \"acute\",        \"comorbidity\": \"diabetes\",      \"true_target\": 0},\n",
    "    {\"symptom\": \"rash\",               \"age_group\": \"young_adult\", \"severity\": \"severe\",   \"duration\": \"chronic\",      \"comorbidity\": \"diabetes\",      \"true_target\": 1},\n",
    "])\n",
    "\n",
    "categorical_features = [\"symptom\", \"age_group\", \"severity\", \"duration\", \"comorbidity\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "encoded_test = test_cases.copy()\n",
    "for col in categorical_features:\n",
    "    encoded_test[col] = encoders[col].transform(encoded_test[col])\n",
    "\n",
    "X_manual = encoded_test[categorical_features]\n",
    "y_true = encoded_test[\"true_target\"].values\n",
    "\n",
    "# Model predictions\n",
    "y_pred = model.predict(X_manual)\n",
    "y_prob = model.predict_proba(X_manual)[:, 1]\n",
    "\n",
    "for i, row in test_cases.iterrows():\n",
    "    print(\n",
    "        f\"Case {i+1}: {row['symptom']}, {row['age_group']}, \"\n",
    "        f\"{row['severity']}, {row['duration']}, {row['comorbidity']} \"\n",
    "        f\"-> true={row['true_target']}, pred={y_pred[i]}, prob={y_prob[i]:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Define categories\n",
    "# -----------------------------\n",
    "\n",
    "symptoms = [\n",
    "    # Respiratory\n",
    "    \"cough\", \"persistent_cough\", \"coughing_blood\",\n",
    "    \"shortness_of_breath\", \"severe_shortness_of_breath\",\n",
    "    \"wheezing\", \"chest_tightness\", \"difficulty_breathing\",\n",
    "\n",
    "    # Cardiac / circulatory\n",
    "    \"chest_pain\", \"severe_chest_pain\",\n",
    "    \"irregular_heartbeat\", \"rapid_heartbeat\",\n",
    "\n",
    "    # Fever / infection\n",
    "    \"fever\", \"high_fever\", \"chills\", \"night_sweats\",\n",
    "\n",
    "    # Neurological\n",
    "    \"headache\", \"severe_headache\", \"migraine\",\n",
    "    \"dizziness\", \"severe_dizziness\",\n",
    "    \"confusion\", \"loss_of_consciousness\", \"seizure\",\n",
    "\n",
    "    # Gastrointestinal\n",
    "    \"abdominal_pain\", \"severe_abdominal_pain\",\n",
    "    \"diarrhea\", \"constipation\",\n",
    "    \"nausea\", \"vomiting\", \"severe_vomiting\",\n",
    "    \"bloody_stool\",\n",
    "\n",
    "    # Genitourinary\n",
    "    \"painful_urination\", \"difficulty_urinating\",\n",
    "    \"blood_in_urine\", \"frequent_urination\",\n",
    "\n",
    "    # Musculoskeletal\n",
    "    \"muscle_pain\", \"joint_pain\",\n",
    "    \"back_pain\", \"neck_pain\", \"stiffness\",\n",
    "\n",
    "    # Edema / swelling\n",
    "    \"swelling\", \"severe_swelling\",\n",
    "\n",
    "    # General / systemic\n",
    "    \"fatigue\", \"extreme_fatigue\", \"weakness\",\n",
    "    \"weight_loss\", \"rapid_weight_loss\",\n",
    "    \"loss_of_appetite\",\n",
    "    \"dehydration\", \"severe_dehydration\",\n",
    "\n",
    "    # Skin / hematologic\n",
    "    \"rash\", \"severe_rash\",\n",
    "    \"pale_skin\", \"bruising\", \"excessive_bruising\",\n",
    "    \"swollen_lymph_nodes\", \"bleeding\",\n",
    "\n",
    "    # Vision\n",
    "    \"vision_problems\", \"severe_vision_loss\",\n",
    "\n",
    "    # Mental health\n",
    "    \"anxiety\", \"severe_anxiety\",\n",
    "    \"panic_attack\",\n",
    "    \"depression\", \"severe_depression\",\n",
    "    \"insomnia\",\n",
    "]\n",
    "\n",
    "age_groups = [\"child\", \"young_adult\", \"adult\", \"senior\"]\n",
    "severity_levels = [\"mild\", \"moderate\", \"severe\"]\n",
    "duration_types = [\"acute\", \"intermittent\", \"chronic\"]\n",
    "comorbidities = [\"none\", \"asthma\", \"diabetes\", \"hypertension\", \"heart_disease\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Risk contribution tables\n",
    "# -----------------------------\n",
    "\n",
    "symptom_risk = {\n",
    "    # Respiratory\n",
    "    \"cough\": 10,\n",
    "    \"persistent_cough\": 20,\n",
    "    \"coughing_blood\": 85,\n",
    "    \"shortness_of_breath\": 55,\n",
    "    \"severe_shortness_of_breath\": 75,\n",
    "    \"wheezing\": 25,\n",
    "    \"chest_tightness\": 35,\n",
    "    \"difficulty_breathing\": 65,\n",
    "\n",
    "    # Cardiac\n",
    "    \"chest_pain\": 70,\n",
    "    \"severe_chest_pain\": 85,\n",
    "    \"irregular_heartbeat\": 80,\n",
    "    \"rapid_heartbeat\": 55,\n",
    "\n",
    "    # Fever / infection\n",
    "    \"fever\": 25,\n",
    "    \"high_fever\": 50,\n",
    "    \"chills\": 20,\n",
    "    \"night_sweats\": 25,\n",
    "\n",
    "    # Neurological\n",
    "    \"headache\": 15,\n",
    "    \"severe_headache\": 45,\n",
    "    \"migraine\": 35,\n",
    "    \"dizziness\": 20,\n",
    "    \"severe_dizziness\": 45,\n",
    "    \"confusion\": 70,\n",
    "    \"loss_of_consciousness\": 95,\n",
    "    \"seizure\": 95,\n",
    "\n",
    "    # GI\n",
    "    \"abdominal_pain\": 25,\n",
    "    \"severe_abdominal_pain\": 65,\n",
    "    \"diarrhea\": 15,\n",
    "    \"constipation\": 10,\n",
    "    \"nausea\": 10,\n",
    "    \"vomiting\": 20,\n",
    "    \"severe_vomiting\": 45,\n",
    "    \"bloody_stool\": 90,\n",
    "\n",
    "    # GU\n",
    "    \"painful_urination\": 25,\n",
    "    \"difficulty_urinating\": 30,\n",
    "    \"blood_in_urine\": 75,\n",
    "    \"frequent_urination\": 20,\n",
    "\n",
    "    # Musculoskeletal\n",
    "    \"muscle_pain\": 15,\n",
    "    \"joint_pain\": 20,\n",
    "    \"back_pain\": 20,\n",
    "    \"neck_pain\": 25,\n",
    "    \"stiffness\": 15,\n",
    "\n",
    "    # Swelling\n",
    "    \"swelling\": 20,\n",
    "    \"severe_swelling\": 50,\n",
    "\n",
    "    # Systemic / general\n",
    "    \"fatigue\": 15,\n",
    "    \"extreme_fatigue\": 35,\n",
    "    \"weakness\": 25,\n",
    "    \"weight_loss\": 35,\n",
    "    \"rapid_weight_loss\": 60,\n",
    "    \"loss_of_appetite\": 30,\n",
    "    \"dehydration\": 35,\n",
    "    \"severe_dehydration\": 70,\n",
    "\n",
    "    # Skin / hematologic\n",
    "    \"rash\": 10,\n",
    "    \"severe_rash\": 35,\n",
    "    \"pale_skin\": 25,\n",
    "    \"bruising\": 20,\n",
    "    \"excessive_bruising\": 50,\n",
    "    \"swollen_lymph_nodes\": 25,\n",
    "    \"bleeding\": 60,\n",
    "\n",
    "    # Vision\n",
    "    \"vision_problems\": 40,\n",
    "    \"severe_vision_loss\": 80,\n",
    "\n",
    "    # Mental health\n",
    "    \"anxiety\": 20,\n",
    "    \"severe_anxiety\": 40,\n",
    "    \"panic_attack\": 45,\n",
    "    \"depression\": 25,\n",
    "    \"severe_depression\": 55,\n",
    "    \"insomnia\": 15,\n",
    "}\n",
    "\n",
    "age_risk = {\n",
    "    \"child\": 10,\n",
    "    \"young_adult\": 5,\n",
    "    \"adult\": 15,\n",
    "    \"senior\": 25,\n",
    "}\n",
    "\n",
    "severity_risk = {\n",
    "    \"mild\": 5,\n",
    "    \"moderate\": 20,\n",
    "    \"severe\": 40,\n",
    "}\n",
    "\n",
    "duration_risk = {\n",
    "    \"acute\": 10,\n",
    "    \"intermittent\": 20,\n",
    "    \"chronic\": 30,\n",
    "}\n",
    "\n",
    "comorbidity_risk = {\n",
    "    \"none\": 0,\n",
    "    \"asthma\": 20,\n",
    "    \"diabetes\": 30,\n",
    "    \"hypertension\": 35,\n",
    "    \"heart_disease\": 45,\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Generate dataset\n",
    "# -----------------------------\n",
    "\n",
    "num_rows = 5000\n",
    "\n",
    "data = {\n",
    "    \"symptom\": [],\n",
    "    \"age_group\": [],\n",
    "    \"severity\": [],\n",
    "    \"duration\": [],\n",
    "    \"comorbidity\": [],\n",
    "    \"risk_score\": [],\n",
    "    \"target\": [],\n",
    "}\n",
    "\n",
    "rng = np.random.default_rng(seed=42)  # for reproducibility\n",
    "\n",
    "for _ in range(num_rows):\n",
    "    sym = rng.choice(symptoms)\n",
    "    age = rng.choice(age_groups)\n",
    "    sev = rng.choice(severity_levels)\n",
    "    dur = rng.choice(duration_types)\n",
    "    com = rng.choice(comorbidities)\n",
    "\n",
    "    # Base risk from components\n",
    "    base = (\n",
    "        symptom_risk[sym]\n",
    "        + age_risk[age]\n",
    "        + severity_risk[sev]\n",
    "        + duration_risk[dur]\n",
    "        + comorbidity_risk[com]\n",
    "    )\n",
    "\n",
    "    # Add noise so it's not perfectly deterministic\n",
    "    noise = rng.integers(-12, 13)  # -12..+12\n",
    "    risk = base + noise\n",
    "\n",
    "    # Clamp to [0, 100]\n",
    "    risk = int(max(0, min(100, risk)))\n",
    "\n",
    "    target = 1 if risk >= 70 else 0\n",
    "\n",
    "    data[\"symptom\"].append(sym)\n",
    "    data[\"age_group\"].append(age)\n",
    "    data[\"severity\"].append(sev)\n",
    "    data[\"duration\"].append(dur)\n",
    "    data[\"comorbidity\"].append(com)\n",
    "    data[\"risk_score\"].append(risk)\n",
    "    data[\"target\"].append(target)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"generated_symptom_risk_data_comprehensive.csv\", index=False)\n",
    "\n",
    "print(\"Saved: generated_symptom_risk_data_comprehensive.csv with\", len(df), \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 1. DATASET GENERATOR (5k rows, comprehensive symptoms)\n",
    "# ============================================\n",
    "\n",
    "def generate_comprehensive_dataset(csv_path: Path, num_rows: int = 5000, seed: int = 42):\n",
    "    # Symptom space (same as we discussed)\n",
    "    symptoms = [\n",
    "        # Respiratory\n",
    "        \"cough\", \"persistent_cough\", \"coughing_blood\",\n",
    "        \"shortness_of_breath\", \"severe_shortness_of_breath\",\n",
    "        \"wheezing\", \"chest_tightness\", \"difficulty_breathing\",\n",
    "\n",
    "        # Cardiac / circulatory\n",
    "        \"chest_pain\", \"severe_chest_pain\",\n",
    "        \"irregular_heartbeat\", \"rapid_heartbeat\",\n",
    "\n",
    "        # Fever / infection\n",
    "        \"fever\", \"high_fever\", \"chills\", \"night_sweats\",\n",
    "\n",
    "        # Neurological\n",
    "        \"headache\", \"severe_headache\", \"migraine\",\n",
    "        \"dizziness\", \"severe_dizziness\",\n",
    "        \"confusion\", \"loss_of_consciousness\", \"seizure\",\n",
    "\n",
    "        # Gastrointestinal\n",
    "        \"abdominal_pain\", \"severe_abdominal_pain\",\n",
    "        \"diarrhea\", \"constipation\",\n",
    "        \"nausea\", \"vomiting\", \"severe_vomiting\",\n",
    "        \"bloody_stool\",\n",
    "\n",
    "        # Genitourinary\n",
    "        \"painful_urination\", \"difficulty_urinating\",\n",
    "        \"blood_in_urine\", \"frequent_urination\",\n",
    "\n",
    "        # Musculoskeletal\n",
    "        \"muscle_pain\", \"joint_pain\",\n",
    "        \"back_pain\", \"neck_pain\", \"stiffness\",\n",
    "\n",
    "        # Edema / swelling\n",
    "        \"swelling\", \"severe_swelling\",\n",
    "\n",
    "        # General / systemic\n",
    "        \"fatigue\", \"extreme_fatigue\", \"weakness\",\n",
    "        \"weight_loss\", \"rapid_weight_loss\",\n",
    "        \"loss_of_appetite\",\n",
    "        \"dehydration\", \"severe_dehydration\",\n",
    "\n",
    "        # Skin / hematologic\n",
    "        \"rash\", \"severe_rash\",\n",
    "        \"pale_skin\", \"bruising\", \"excessive_bruising\",\n",
    "        \"swollen_lymph_nodes\", \"bleeding\",\n",
    "\n",
    "        # Vision\n",
    "        \"vision_problems\", \"severe_vision_loss\",\n",
    "\n",
    "        # Mental health\n",
    "        \"anxiety\", \"severe_anxiety\",\n",
    "        \"panic_attack\",\n",
    "        \"depression\", \"severe_depression\",\n",
    "        \"insomnia\",\n",
    "    ]\n",
    "\n",
    "    age_groups = [\"child\", \"young_adult\", \"adult\", \"senior\"]\n",
    "    severity_levels = [\"mild\", \"moderate\", \"severe\"]\n",
    "    duration_types = [\"acute\", \"intermittent\", \"chronic\"]\n",
    "    comorbidities = [\"none\", \"asthma\", \"diabetes\", \"hypertension\", \"heart_disease\"]\n",
    "\n",
    "    # Risk contribution tables\n",
    "    symptom_risk = {\n",
    "        # Respiratory\n",
    "        \"cough\": 10,\n",
    "        \"persistent_cough\": 20,\n",
    "        \"coughing_blood\": 85,\n",
    "        \"shortness_of_breath\": 55,\n",
    "        \"severe_shortness_of_breath\": 75,\n",
    "        \"wheezing\": 25,\n",
    "        \"chest_tightness\": 35,\n",
    "        \"difficulty_breathing\": 65,\n",
    "\n",
    "        # Cardiac\n",
    "        \"chest_pain\": 70,\n",
    "        \"severe_chest_pain\": 85,\n",
    "        \"irregular_heartbeat\": 80,\n",
    "        \"rapid_heartbeat\": 55,\n",
    "\n",
    "        # Fever / infection\n",
    "        \"fever\": 25,\n",
    "        \"high_fever\": 50,\n",
    "        \"chills\": 20,\n",
    "        \"night_sweats\": 25,\n",
    "\n",
    "        # Neurological\n",
    "        \"headache\": 15,\n",
    "        \"severe_headache\": 45,\n",
    "        \"migraine\": 35,\n",
    "        \"dizziness\": 20,\n",
    "        \"severe_dizziness\": 45,\n",
    "        \"confusion\": 70,\n",
    "        \"loss_of_consciousness\": 95,\n",
    "        \"seizure\": 95,\n",
    "\n",
    "        # GI\n",
    "        \"abdominal_pain\": 25,\n",
    "        \"severe_abdominal_pain\": 65,\n",
    "        \"diarrhea\": 15,\n",
    "        \"constipation\": 10,\n",
    "        \"nausea\": 10,\n",
    "        \"vomiting\": 20,\n",
    "        \"severe_vomiting\": 45,\n",
    "        \"bloody_stool\": 90,\n",
    "\n",
    "        # GU\n",
    "        \"painful_urination\": 25,\n",
    "        \"difficulty_urinating\": 30,\n",
    "        \"blood_in_urine\": 75,\n",
    "        \"frequent_urination\": 20,\n",
    "\n",
    "        # Musculoskeletal\n",
    "        \"muscle_pain\": 15,\n",
    "        \"joint_pain\": 20,\n",
    "        \"back_pain\": 20,\n",
    "        \"neck_pain\": 25,\n",
    "        \"stiffness\": 15,\n",
    "\n",
    "        # Swelling\n",
    "        \"swelling\": 20,\n",
    "        \"severe_swelling\": 50,\n",
    "\n",
    "        # Systemic / general\n",
    "        \"fatigue\": 15,\n",
    "        \"extreme_fatigue\": 35,\n",
    "        \"weakness\": 25,\n",
    "        \"weight_loss\": 35,\n",
    "        \"rapid_weight_loss\": 60,\n",
    "        \"loss_of_appetite\": 30,\n",
    "        \"dehydration\": 35,\n",
    "        \"severe_dehydration\": 70,\n",
    "\n",
    "        # Skin / hematologic\n",
    "        \"rash\": 10,\n",
    "        \"severe_rash\": 35,\n",
    "        \"pale_skin\": 25,\n",
    "        \"bruising\": 20,\n",
    "        \"excessive_bruising\": 50,\n",
    "        \"swollen_lymph_nodes\": 25,\n",
    "        \"bleeding\": 60,\n",
    "\n",
    "        # Vision\n",
    "        \"vision_problems\": 40,\n",
    "        \"severe_vision_loss\": 80,\n",
    "\n",
    "        # Mental health\n",
    "        \"anxiety\": 20,\n",
    "        \"severe_anxiety\": 40,\n",
    "        \"panic_attack\": 45,\n",
    "        \"depression\": 25,\n",
    "        \"severe_depression\": 55,\n",
    "        \"insomnia\": 15,\n",
    "    }\n",
    "\n",
    "    age_risk = {\n",
    "        \"child\": 10,\n",
    "        \"young_adult\": 5,\n",
    "        \"adult\": 15,\n",
    "        \"senior\": 25,\n",
    "    }\n",
    "\n",
    "    severity_risk = {\n",
    "        \"mild\": 5,\n",
    "        \"moderate\": 20,\n",
    "        \"severe\": 40,\n",
    "    }\n",
    "\n",
    "    duration_risk = {\n",
    "        \"acute\": 10,\n",
    "        \"intermittent\": 20,\n",
    "        \"chronic\": 30,\n",
    "    }\n",
    "\n",
    "    comorbidity_risk = {\n",
    "        \"none\": 0,\n",
    "        \"asthma\": 20,\n",
    "        \"diabetes\": 30,\n",
    "        \"hypertension\": 35,\n",
    "        \"heart_disease\": 45,\n",
    "    }\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    data = {\n",
    "        \"symptom\": [],\n",
    "        \"age_group\": [],\n",
    "        \"severity\": [],\n",
    "        \"duration\": [],\n",
    "        \"comorbidity\": [],\n",
    "        \"risk_score\": [],\n",
    "    }\n",
    "\n",
    "    for _ in range(num_rows):\n",
    "        sym = rng.choice(symptoms)\n",
    "        age = rng.choice(age_groups)\n",
    "        sev = rng.choice(severity_levels)\n",
    "        dur = rng.choice(duration_types)\n",
    "        com = rng.choice(comorbidities)\n",
    "\n",
    "        base = (\n",
    "            symptom_risk[sym]\n",
    "            + age_risk[age]\n",
    "            + severity_risk[sev]\n",
    "            + duration_risk[dur]\n",
    "            + comorbidity_risk[com]\n",
    "        )\n",
    "\n",
    "        noise = rng.integers(-12, 13)  # -12..+12\n",
    "        risk = base + noise\n",
    "        risk = int(max(0, min(100, risk)))\n",
    "\n",
    "        data[\"symptom\"].append(sym)\n",
    "        data[\"age_group\"].append(age)\n",
    "        data[\"severity\"].append(sev)\n",
    "        data[\"duration\"].append(dur)\n",
    "        data[\"comorbidity\"].append(com)\n",
    "        data[\"risk_score\"].append(risk)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Generated dataset at {csv_path} with {len(df)} rows.\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. TRAIN MODEL\n",
    "# ============================================\n",
    "\n",
    "def train_model(csv_path: Path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Binary target: high risk if score >= 70\n",
    "    df[\"target\"] = (df[\"risk_score\"] >= 70).astype(int)\n",
    "\n",
    "    categorical_features = [\"symptom\", \"age_group\", \"severity\", \"duration\", \"comorbidity\"]\n",
    "    encoders = {}\n",
    "\n",
    "    # Fit encoders and transform categorical columns\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        encoders[col] = le\n",
    "\n",
    "    X = df[categorical_features]\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nTest accuracy: {acc:.3f}\\n\")\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return model, encoders\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. MANUAL TEST CASES\n",
    "# ============================================\n",
    "\n",
    "def run_manual_test_cases(model, encoders):\n",
    "    categorical_features = [\"symptom\", \"age_group\", \"severity\", \"duration\", \"comorbidity\"]\n",
    "\n",
    "    # Hand-crafted scenarios using only valid categories\n",
    "    # expected_risk is just an intuition for you (not used by code)\n",
    "    test_cases = pd.DataFrame([\n",
    "        {\n",
    "            \"symptom\": \"cough\",\n",
    "            \"age_group\": \"young_adult\",\n",
    "            \"severity\": \"mild\",\n",
    "            \"duration\": \"acute\",\n",
    "            \"comorbidity\": \"none\",\n",
    "            \"expected_risk_comment\": \"clearly low\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"fever\",\n",
    "            \"age_group\": \"child\",\n",
    "            \"severity\": \"mild\",\n",
    "            \"duration\": \"acute\",\n",
    "            \"comorbidity\": \"none\",\n",
    "            \"expected_risk_comment\": \"low-to-moderate\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"fever\",\n",
    "            \"age_group\": \"senior\",\n",
    "            \"severity\": \"severe\",\n",
    "            \"duration\": \"chronic\",\n",
    "            \"comorbidity\": \"diabetes\",\n",
    "            \"expected_risk_comment\": \"very high\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"chest_pain\",\n",
    "            \"age_group\": \"adult\",\n",
    "            \"severity\": \"moderate\",\n",
    "            \"duration\": \"acute\",\n",
    "            \"comorbidity\": \"none\",\n",
    "            \"expected_risk_comment\": \"high (cardiac)\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"severe_chest_pain\",\n",
    "            \"age_group\": \"senior\",\n",
    "            \"severity\": \"severe\",\n",
    "            \"duration\": \"chronic\",\n",
    "            \"comorbidity\": \"heart_disease\",\n",
    "            \"expected_risk_comment\": \"extremely high\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"shortness_of_breath\",\n",
    "            \"age_group\": \"adult\",\n",
    "            \"severity\": \"moderate\",\n",
    "            \"duration\": \"chronic\",\n",
    "            \"comorbidity\": \"asthma\",\n",
    "            \"expected_risk_comment\": \"high\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"cough\",\n",
    "            \"age_group\": \"senior\",\n",
    "            \"severity\": \"severe\",\n",
    "            \"duration\": \"chronic\",\n",
    "            \"comorbidity\": \"heart_disease\",\n",
    "            \"expected_risk_comment\": \"moderately high\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"panic_attack\",\n",
    "            \"age_group\": \"young_adult\",\n",
    "            \"severity\": \"mild\",\n",
    "            \"duration\": \"acute\",\n",
    "            \"comorbidity\": \"none\",\n",
    "            \"expected_risk_comment\": \"medium\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"severe_depression\",\n",
    "            \"age_group\": \"young_adult\",\n",
    "            \"severity\": \"severe\",\n",
    "            \"duration\": \"intermittent\",\n",
    "            \"comorbidity\": \"diabetes\",\n",
    "            \"expected_risk_comment\": \"very high\"\n",
    "        },\n",
    "        {\n",
    "            \"symptom\": \"bloody_stool\",\n",
    "            \"age_group\": \"adult\",\n",
    "            \"severity\": \"mild\",\n",
    "            \"duration\": \"acute\",\n",
    "            \"comorbidity\": \"none\",\n",
    "            \"expected_risk_comment\": \"very high (GI bleed-like)\"\n",
    "        },\n",
    "    ])\n",
    "\n",
    "    encoded = test_cases.copy()\n",
    "    for col in categorical_features:\n",
    "        encoded[col] = encoders[col].transform(encoded[col])\n",
    "\n",
    "    X_manual = encoded[categorical_features]\n",
    "    preds = model.predict(X_manual)\n",
    "    probs = model.predict_proba(X_manual)[:, 1]\n",
    "\n",
    "    print(\"\\nManual test cases predictions:\")\n",
    "    for i, row in test_cases.iterrows():\n",
    "        print(\n",
    "            f\"Case {i+1}: \"\n",
    "            f\"{row['symptom']}, {row['age_group']}, \"\n",
    "            f\"{row['severity']}, {row['duration']}, {row['comorbidity']} | \"\n",
    "            f\"expected_comment={row['expected_risk_comment']} -> \"\n",
    "            f\"predicted_high_risk={int(preds[i])}, prob={probs[i]:.3f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. MAIN\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = Path(\"generated_symptom_risk_data_comprehensive.csv\")\n",
    "\n",
    "    if not csv_path.exists():\n",
    "        generate_comprehensive_dataset(csv_path, num_rows=5000, seed=42)\n",
    "    else:\n",
    "        print(f\"Using existing dataset at {csv_path}\")\n",
    "\n",
    "    model, encoders = train_model(csv_path)\n",
    "    run_manual_test_cases(model, encoders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c83564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MEDICAL RISK SCORING SYSTEM WITH BIOBERT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: GENERATE COMPREHENSIVE SYNTHETIC MEDICAL DATASET\n",
    "# ============================================================================\n",
    "\n",
    "def generate_medical_dataset(n_samples=2000):\n",
    "    \"\"\"Generate synthetic patient data with symptoms mapped to risk scores\"\"\"\n",
    "    \n",
    "    print(\"\\n[1/6] Generating synthetic medical dataset...\")\n",
    "    \n",
    "    # Define symptom categories\n",
    "    symptoms_dict = {\n",
    "        'respiratory': ['shortness of breath', 'persistent cough', 'wheezing', \n",
    "                       'chest tightness', 'rapid breathing', 'coughing up blood'],\n",
    "        'cardiac': ['chest pain', 'irregular heartbeat', 'palpitations', \n",
    "                   'dizziness', 'fainting', 'leg swelling'],\n",
    "        'neurological': ['severe headache', 'confusion', 'vision changes', \n",
    "                        'numbness', 'weakness', 'seizures', 'difficulty speaking'],\n",
    "        'gastrointestinal': ['abdominal pain', 'nausea', 'vomiting', \n",
    "                            'diarrhea', 'blood in stool', 'weight loss'],\n",
    "        'systemic': ['high fever', 'fatigue', 'night sweats', 'chills', \n",
    "                    'unexplained weight loss', 'loss of appetite'],\n",
    "        'other': ['skin rash', 'joint pain', 'frequent urination', \n",
    "                 'excessive thirst', 'blurred vision']\n",
    "    }\n",
    "    \n",
    "    # Flatten symptoms\n",
    "    all_symptoms = [s for symptoms in symptoms_dict.values() for s in symptoms]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Randomly select 2-6 symptoms per patient\n",
    "        n_symptoms = np.random.randint(2, 7)\n",
    "        patient_symptoms = np.random.choice(all_symptoms, n_symptoms, replace=False)\n",
    "        \n",
    "        # Demographics\n",
    "        age = np.random.randint(18, 90)\n",
    "        gender = np.random.choice(['Male', 'Female'])\n",
    "        \n",
    "        # Vital signs\n",
    "        temperature = round(np.random.uniform(97.0, 104.0), 1)\n",
    "        heart_rate = np.random.randint(50, 140)\n",
    "        blood_pressure_sys = np.random.randint(90, 180)\n",
    "        blood_pressure_dia = np.random.randint(60, 120)\n",
    "        respiratory_rate = np.random.randint(12, 30)\n",
    "        oxygen_saturation = round(np.random.uniform(85, 100), 1)\n",
    "        \n",
    "        # Medical history\n",
    "        has_diabetes = np.random.choice([0, 1], p=[0.85, 0.15])\n",
    "        has_hypertension = np.random.choice([0, 1], p=[0.75, 0.25])\n",
    "        has_heart_disease = np.random.choice([0, 1], p=[0.90, 0.10])\n",
    "        smoking_status = np.random.choice([0, 1], p=[0.80, 0.20])\n",
    "        \n",
    "        # Duration of symptoms\n",
    "        symptom_duration_days = np.random.randint(1, 30)\n",
    "        \n",
    "        # Calculate risk score (0-100) based on multiple factors\n",
    "        risk_score = 0\n",
    "        \n",
    "        # Age factor (older = higher risk)\n",
    "        risk_score += (age - 18) / 72 * 15  # Max 15 points\n",
    "        \n",
    "        # Symptom severity\n",
    "        critical_symptoms = ['chest pain', 'coughing up blood', 'seizures', \n",
    "                            'difficulty speaking', 'confusion', 'fainting']\n",
    "        critical_count = sum(1 for s in patient_symptoms if s in critical_symptoms)\n",
    "        risk_score += critical_count * 10  # Up to 60 points for critical symptoms\n",
    "        risk_score += (n_symptoms - 2) * 3  # More symptoms = higher risk\n",
    "        \n",
    "        # Vital signs\n",
    "        if temperature > 102:\n",
    "            risk_score += 8\n",
    "        if heart_rate > 100 or heart_rate < 60:\n",
    "            risk_score += 6\n",
    "        if blood_pressure_sys > 140:\n",
    "            risk_score += 7\n",
    "        if oxygen_saturation < 95:\n",
    "            risk_score += 10\n",
    "        if respiratory_rate > 20:\n",
    "            risk_score += 5\n",
    "        \n",
    "        # Medical history\n",
    "        risk_score += has_diabetes * 5\n",
    "        risk_score += has_hypertension * 5\n",
    "        risk_score += has_heart_disease * 8\n",
    "        risk_score += smoking_status * 4\n",
    "        \n",
    "        # Duration (longer duration without treatment = higher risk)\n",
    "        if symptom_duration_days > 14:\n",
    "            risk_score += 8\n",
    "        \n",
    "        # Normalize to 0-100 and add some randomness\n",
    "        risk_score = min(100, max(0, risk_score + np.random.uniform(-5, 5)))\n",
    "        \n",
    "        # Create symptom text description\n",
    "        symptom_text = f\"Patient presents with {', '.join(patient_symptoms)}. \"\n",
    "        symptom_text += f\"Duration: {symptom_duration_days} days. \"\n",
    "        \n",
    "        # Create comprehensive clinical text\n",
    "        clinical_text = symptom_text\n",
    "        clinical_text += f\"Age: {age}, Gender: {gender}. \"\n",
    "        clinical_text += f\"Vitals - Temp: {temperature}F, HR: {heart_rate} bpm, \"\n",
    "        clinical_text += f\"BP: {blood_pressure_sys}/{blood_pressure_dia} mmHg, \"\n",
    "        clinical_text += f\"RR: {respiratory_rate}, SpO2: {oxygen_saturation}%. \"\n",
    "        \n",
    "        history = []\n",
    "        if has_diabetes:\n",
    "            history.append(\"diabetes\")\n",
    "        if has_hypertension:\n",
    "            history.append(\"hypertension\")\n",
    "        if has_heart_disease:\n",
    "            history.append(\"heart disease\")\n",
    "        if smoking_status:\n",
    "            history.append(\"smoking\")\n",
    "        \n",
    "        if history:\n",
    "            clinical_text += f\"Medical history: {', '.join(history)}.\"\n",
    "        \n",
    "        data.append({\n",
    "            'patient_id': f'PT{i+1:05d}',\n",
    "            'age': age,\n",
    "            'gender': gender,\n",
    "            'symptoms': '; '.join(patient_symptoms),\n",
    "            'symptom_duration_days': symptom_duration_days,\n",
    "            'temperature_f': temperature,\n",
    "            'heart_rate': heart_rate,\n",
    "            'blood_pressure_systolic': blood_pressure_sys,\n",
    "            'blood_pressure_diastolic': blood_pressure_dia,\n",
    "            'respiratory_rate': respiratory_rate,\n",
    "            'oxygen_saturation': oxygen_saturation,\n",
    "            'diabetes': has_diabetes,\n",
    "            'hypertension': has_hypertension,\n",
    "            'heart_disease': has_heart_disease,\n",
    "            'smoking': smoking_status,\n",
    "            'clinical_text': clinical_text,\n",
    "            'risk_score': round(risk_score, 2)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('patient_risk_dataset.csv', index=False)\n",
    "    print(f\" Generated {n_samples} patient records\")\n",
    "    print(f\" Saved to 'patient_risk_dataset.csv'\")\n",
    "    print(f\"\\nRisk Score Statistics:\")\n",
    "    print(f\"  Mean: {df['risk_score'].mean():.2f}\")\n",
    "    print(f\"  Std:  {df['risk_score'].std():.2f}\")\n",
    "    print(f\"  Min:  {df['risk_score'].min():.2f}\")\n",
    "    print(f\"  Max:  {df['risk_score'].max():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DEFINE BIOBERT DATASET CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class MedicalRiskDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for medical risk scoring\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, risk_scores, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.risk_scores = risk_scores\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        risk_score = self.risk_scores[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'risk_score': torch.tensor(risk_score, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: DEFINE BIOBERT RISK SCORING MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class BioBERTRiskScorer(nn.Module):\n",
    "    \"\"\"BioBERT-based model for medical risk scoring\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='dmis-lab/biobert-v1.1', dropout=0.3):\n",
    "        super(BioBERTRiskScorer, self).__init__()\n",
    "        self.biobert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.biobert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        risk_score = self.regressor(pooled_output)\n",
    "        return risk_score.squeeze()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        risk_scores = batch['risk_score'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(input_ids, attention_mask)\n",
    "        loss = criterion(predictions, risk_scores)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            risk_scores = batch['risk_score'].to(device)\n",
    "            \n",
    "            predictions = model(input_ids, attention_mask)\n",
    "            loss = criterion(predictions, risk_scores)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(risk_scores.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    mse = mean_squared_error(all_targets, all_predictions)\n",
    "    r2 = r2_score(all_targets, all_predictions)\n",
    "    \n",
    "    return avg_loss, mse, r2, all_predictions, all_targets\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    # Generate dataset\n",
    "    df = generate_medical_dataset(n_samples=2000)\n",
    "    \n",
    "    print(\"\\n[2/6] Loading BioBERT tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
    "    print(\" Tokenizer loaded\")\n",
    "    \n",
    "    print(\"\\n[3/6] Preparing data...\")\n",
    "    # Split data\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MedicalRiskDataset(\n",
    "        train_df['clinical_text'].values,\n",
    "        train_df['risk_score'].values,\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    test_dataset = MedicalRiskDataset(\n",
    "        test_df['clinical_text'].values,\n",
    "        test_df['risk_score'].values,\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    print(f\" Training samples: {len(train_dataset)}\")\n",
    "    print(f\" Testing samples: {len(test_dataset)}\")\n",
    "    \n",
    "    print(\"\\n[4/6] Initializing BioBERT model...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\" Using device: {device}\")\n",
    "    \n",
    "    model = BioBERTRiskScorer().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    print(f\" Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    \n",
    "    print(\"\\n[5/6] Training model...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    num_epochs = 3  # Reduce for faster execution\n",
    "    best_r2 = -float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, mse, r2, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "        print(f\"  Val MSE:    {mse:.4f}\")\n",
    "        print(f\"  Val R:     {r2:.4f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            torch.save(model.state_dict(), 'best_biobert_risk_model.pth')\n",
    "    \n",
    "    print(\"\\n[6/6] Final Evaluation...\")\n",
    "    model.load_state_dict(torch.load('best_biobert_risk_model.pth'))\n",
    "    val_loss, mse, r2, predictions, targets = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {np.sqrt(mse):.4f}\")\n",
    "    print(f\"  R Score: {r2:.4f}\")\n",
    "    \n",
    "    # Create risk categories\n",
    "    predictions = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    def categorize_risk(score):\n",
    "        if score < 30:\n",
    "            return 'Low'\n",
    "        elif score < 60:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'High'\n",
    "    \n",
    "    pred_categories = [categorize_risk(s) for s in predictions]\n",
    "    true_categories = [categorize_risk(s) for s in targets]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RISK CLASSIFICATION REPORT\")\n",
    "    print(\"=\" * 70)\n",
    "    print(classification_report(true_categories, pred_categories))\n",
    "    \n",
    "    # Show sample predictions\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SAMPLE PREDICTIONS (First 10 test patients)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    sample_df = test_df.head(10).copy()\n",
    "    sample_predictions = predictions[:10]\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
    "        print(f\"\\nPatient {row['patient_id']}:\")\n",
    "        print(f\"  Symptoms: {row['symptoms'][:80]}...\")\n",
    "        print(f\"  Actual Risk Score: {row['risk_score']:.2f} ({categorize_risk(row['risk_score'])})\")\n",
    "        print(f\"  Predicted Score:   {sample_predictions[idx]:.2f} ({categorize_risk(sample_predictions[idx])})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\" Dataset saved: patient_risk_dataset.csv\")\n",
    "    print(f\" Model saved: best_biobert_risk_model.pth\")\n",
    "    print(f\" Total patients: {len(df)}\")\n",
    "    print(f\" Model R Score: {r2:.4f}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc9ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphawave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
